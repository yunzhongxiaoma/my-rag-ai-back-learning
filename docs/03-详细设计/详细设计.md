# 详细设计文档

## 1. 接口设计

### 1.1 用户管理接口

#### 1.1.1 用户注册接口
```http
POST /api/user/register
Content-Type: application/json

Request Body:
{
    "username": "string",
    "password": "string", 
    "email": "string",
    "nickname": "string"
}

Response:
{
    "code": 200,
    "message": "注册成功",
    "data": {
        "userId": "long",
        "username": "string",
        "nickname": "string",
        "createTime": "datetime"
    }
}
```

#### 1.1.2 用户登录接口
```http
POST /api/user/login
Content-Type: application/json

Request Body:
{
    "username": "string",
    "password": "string"
}

Response:
{
    "code": 200,
    "message": "登录成功",
    "data": {
        "token": "string",
        "userInfo": {
            "userId": "long",
            "username": "string",
            "nickname": "string",
            "role": "string"
        }
    }
}
```

### 1.2 文档管理接口

#### 1.2.1 文档上传接口
```http
POST /api/document/upload
Content-Type: multipart/form-data
Authorization: Bearer {token}

Request Body:
- file: MultipartFile
- description: string (optional)
- tags: string (optional)

Response:
{
    "code": 200,
    "message": "上传成功",
    "data": {
        "documentId": "long",
        "fileName": "string",
        "fileSize": "long",
        "uploadTime": "datetime",
        "status": "PROCESSING"
    }
}
```

#### 1.2.2 文档列表查询接口
```http
GET /api/document/list
Authorization: Bearer {token}

Query Parameters:
- page: int (default: 1)
- size: int (default: 10)
- keyword: string (optional)
- status: string (optional)

Response:
{
    "code": 200,
    "message": "查询成功",
    "data": {
        "total": "long",
        "pages": "int",
        "current": "int",
        "records": [
            {
                "documentId": "long",
                "fileName": "string",
                "fileSize": "long",
                "status": "string",
                "uploadTime": "datetime",
                "processTime": "datetime"
            }
        ]
    }
}
```

### 1.3 智能问答接口

#### 1.3.1 问答对话接口
```http
POST /api/chat/ask
Content-Type: application/json
Authorization: Bearer {token}

Request Body:
{
    "question": "string",
    "sessionId": "string",
    "documentIds": ["long"] (optional),
    "temperature": "double" (optional, default: 0.7),
    "maxTokens": "int" (optional, default: 1000)
}

Response:
{
    "code": 200,
    "message": "回答成功",
    "data": {
        "answer": "string",
        "sessionId": "string",
        "references": [
            {
                "documentId": "long",
                "fileName": "string",
                "content": "string",
                "similarity": "double"
            }
        ],
        "responseTime": "long"
    }
}
```

#### 1.3.2 对话历史查询接口
```http
GET /api/chat/history
Authorization: Bearer {token}

Query Parameters:
- sessionId: string
- page: int (default: 1)
- size: int (default: 20)

Response:
{
    "code": 200,
    "message": "查询成功",
    "data": {
        "sessionId": "string",
        "messages": [
            {
                "messageId": "long",
                "type": "USER|ASSISTANT",
                "content": "string",
                "timestamp": "datetime"
            }
        ]
    }
}
```

### 1.4 向量管理接口

#### 1.4.1 向量检索接口
```http
POST /api/vector/search
Content-Type: application/json
Authorization: Bearer {token}

Request Body:
{
    "query": "string",
    "topK": "int" (default: 10),
    "threshold": "double" (default: 0.7),
    "documentIds": ["long"] (optional)
}

Response:
{
    "code": 200,
    "message": "检索成功",
    "data": {
        "results": [
            {
                "documentId": "long",
                "content": "string",
                "similarity": "double",
                "metadata": "object"
            }
        ],
        "searchTime": "long"
    }
}
```

## 2. 数据库表结构设计

### 2.1 用户相关表

#### 2.1.1 用户表 (tb_user)
```sql
CREATE TABLE `tb_user` (
    `id` INT NOT NULL AUTO_INCREMENT,
    `name` VARCHAR(255) NOT NULL COMMENT '姓名',
    `user_name` VARCHAR(255) NOT NULL COMMENT '用户名',
    `password` VARCHAR(255) NOT NULL COMMENT '密码',
    `phone` VARCHAR(255) NOT NULL COMMENT '手机号',
    `sex` VARCHAR(255) NOT NULL COMMENT '性别',
    `id_number` VARCHAR(255) NOT NULL COMMENT '身份证号',
    `status` INT NOT NULL DEFAULT 1 COMMENT '状态 0：禁用 1：启用',
    `create_time` DATE COMMENT '创建时间',
    `update_time` DATE COMMENT '更新时间',
    `create_user` BIGINT COMMENT '创建人',
    `update_user` BIGINT COMMENT '修改人',
    PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=666498 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='用户表';
```

### 2.2 向量存储相关表

#### 2.2.1 向量存储表 (vector_store)
```sql
CREATE TABLE `vector_store` (
    `id` BIGINT NOT NULL AUTO_INCREMENT COMMENT '主键ID',
    `content` TEXT,
    `metadata` JSON,
    `embedding` JSON COMMENT '向量数据，存储为JSON数组，原PostgreSQL为vector(1536)',
    PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
```

#### 2.2.2 阿里云OSS文件表 (ali_oss_file)
```sql
CREATE TABLE `ali_oss_file` (
    `id` BIGINT NOT NULL AUTO_INCREMENT,
    `file_name` VARCHAR(255) COMMENT '文件名',
    `url` VARCHAR(500) COMMENT '链接地址',
    `vector_id` TEXT COMMENT '该文件分割出的多段向量文本ID',
    `create_time` TIMESTAMP NULL DEFAULT NULL COMMENT '创建时间',
    `update_time` TIMESTAMP NULL DEFAULT NULL COMMENT '更新时间',
    PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='阿里云OSS文件表';
```

### 2.3 系统管理相关表

#### 2.3.1 日志信息表 (log_info)
```sql
CREATE TABLE `log_info` (
    `id` BIGINT NOT NULL AUTO_INCREMENT,
    `method_name` VARCHAR(255) COMMENT '方法名',
    `class_name` VARCHAR(255) COMMENT '类目',
    `request_time` DATE COMMENT '请求时间戳',
    `request_params` TEXT COMMENT '请求参数',
    `response` TEXT COMMENT '响应结果',
    PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='日志信息表';
```

#### 2.3.2 敏感词表 (sensitive_word)
```sql
CREATE TABLE `sensitive_word` (
    `id` INT NOT NULL AUTO_INCREMENT,
    `word` VARCHAR(255) COMMENT '敏感词内容',
    `category` VARCHAR(255) COMMENT '敏感词类别',
    `status` VARCHAR(50) COMMENT '敏感词状态',
    `created_at` VARCHAR(50) COMMENT '创建时间戳',
    `updated_at` VARCHAR(50) COMMENT '更新时间戳',
    PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='敏感词表';
```

#### 2.3.3 敏感词分类表 (sensitive_category)
```sql
CREATE TABLE `sensitive_category` (
    `id` INT NOT NULL AUTO_INCREMENT,
    `category_name` VARCHAR(255) COMMENT '分类名',
    `created_time` DATE COMMENT '创建时间',
    `update_time` DATE COMMENT '更新时间',
    `status` VARCHAR(50) COMMENT '状态',
    PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='敏感词分类表';
```

#### 2.3.4 词频统计表 (word_frequency)
```sql
CREATE TABLE `word_frequency` (
    `id` INT NOT NULL AUTO_INCREMENT,
    `word` VARCHAR(255) COMMENT '分词',
    `count_num` INT COMMENT '出现频次',
    `business_type` VARCHAR(255) COMMENT '业务类型',
    `create_time` DATE COMMENT '创建时间',
    `update_time` DATE COMMENT '更新时间',
    PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='词频统计表';
```

### 2.4 表关系说明

#### 2.4.1 核心表关系
- **tb_user**: 用户基础信息表，系统的核心用户数据
- **vector_store**: 向量存储表，存储文档的向量化数据（从PostgreSQL迁移而来）
- **ali_oss_file**: 文件管理表，记录上传到阿里云OSS的文件信息及其对应的向量ID

#### 2.4.2 业务流程关系
1. **文档上传流程**: 用户上传文件 → ali_oss_file记录文件信息 → 文档向量化 → vector_store存储向量数据
2. **敏感词管理**: sensitive_category定义分类 → sensitive_word存储具体敏感词
3. **系统监控**: log_info记录系统操作日志，word_frequency统计词频信息

#### 2.4.3 数据迁移说明
- **vector_store表**: 原PostgreSQL的vector(1536)字段改为MySQL的JSON字段存储
- **embedding字段**: 向量数据以JSON数组格式存储，保持与Milvus的兼容性
- **metadata字段**: 使用MySQL的JSON类型存储元数据信息
    update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    
    INDEX idx_config_key (config_key)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='系统配置表';
```

## 3. 核心算法设计

### 3.1 文档处理算法

#### 3.1.1 文档分块算法伪代码
```python
def chunk_document(document_content, chunk_size=1000, overlap=200):
    """
    文档分块算法
    Args:
        document_content: 文档内容
        chunk_size: 分块大小
        overlap: 重叠大小
    Returns:
        chunks: 分块列表
    """
    chunks = []
    sentences = split_sentences(document_content)
    
    current_chunk = ""
    current_size = 0
    
    for sentence in sentences:
        sentence_size = len(sentence)
        
        if current_size + sentence_size > chunk_size and current_chunk:
            # 保存当前分块
            chunks.append({
                'content': current_chunk.strip(),
                'size': current_size,
                'index': len(chunks)
            })
            
            # 处理重叠
            if overlap > 0:
                overlap_content = get_overlap_content(current_chunk, overlap)
                current_chunk = overlap_content + " " + sentence
                current_size = len(overlap_content) + sentence_size
            else:
                current_chunk = sentence
                current_size = sentence_size
        else:
            current_chunk += " " + sentence
            current_size += sentence_size
    
    # 处理最后一个分块
    if current_chunk.strip():
        chunks.append({
            'content': current_chunk.strip(),
            'size': current_size,
            'index': len(chunks)
        })
    
    return chunks
```

#### 3.1.2 向量化处理算法伪代码
```python
def vectorize_chunks(chunks, embedding_model):
    """
    分块向量化算法
    Args:
        chunks: 文档分块列表
        embedding_model: 向量化模型
    Returns:
        vectors: 向量列表
    """
    vectors = []
    batch_size = 32
    
    for i in range(0, len(chunks), batch_size):
        batch_chunks = chunks[i:i + batch_size]
        batch_texts = [chunk['content'] for chunk in batch_chunks]
        
        # 批量向量化
        batch_vectors = embedding_model.encode(batch_texts)
        
        for j, vector in enumerate(batch_vectors):
            vectors.append({
                'chunk_id': batch_chunks[j]['index'],
                'vector': vector.tolist(),
                'content': batch_chunks[j]['content'],
                'metadata': {
                    'chunk_size': batch_chunks[j]['size'],
                    'chunk_index': batch_chunks[j]['index']
                }
            })
    
    return vectors
```

### 3.2 检索算法设计

#### 3.2.1 向量检索算法伪代码
```python
def vector_search(query, milvus_client, top_k=10, threshold=0.7):
    """
    向量检索算法
    Args:
        query: 查询文本
        milvus_client: Milvus客户端
        top_k: 返回结果数量
        threshold: 相似度阈值
    Returns:
        results: 检索结果
    """
    # 查询向量化
    query_vector = embedding_model.encode([query])[0]
    
    # 构建检索参数
    search_params = {
        "metric_type": "COSINE",
        "params": {"nprobe": 16}
    }
    
    # 执行向量检索
    search_results = milvus_client.search(
        collection_name="vector_store",
        data=[query_vector.tolist()],
        anns_field="vector",
        param=search_params,
        limit=top_k * 2,  # 获取更多结果用于过滤
        output_fields=["content", "metadata", "document_id"]
    )
    
    # 结果过滤和排序
    filtered_results = []
    for result in search_results[0]:
        if result.distance >= threshold:
            filtered_results.append({
                'id': result.id,
                'content': result.entity.get('content'),
                'similarity': result.distance,
                'document_id': result.entity.get('document_id'),
                'metadata': result.entity.get('metadata')
            })
    
    # 去重和重排序
    unique_results = remove_duplicates(filtered_results)
    return unique_results[:top_k]
```

### 3.3 RAG生成算法

#### 3.3.1 上下文构建算法伪代码
```python
def build_rag_context(query, search_results, max_context_length=4000):
    """
    RAG上下文构建算法
    Args:
        query: 用户查询
        search_results: 检索结果
        max_context_length: 最大上下文长度
    Returns:
        context: 构建的上下文
    """
    context_parts = []
    current_length = 0
    
    # 系统提示词
    system_prompt = "基于以下文档内容回答用户问题，如果文档中没有相关信息，请明确说明。"
    context_parts.append(system_prompt)
    current_length += len(system_prompt)
    
    # 添加检索到的文档内容
    for i, result in enumerate(search_results):
        content = result['content']
        content_length = len(content)
        
        if current_length + content_length > max_context_length:
            # 截断内容
            remaining_length = max_context_length - current_length - 100
            if remaining_length > 0:
                content = content[:remaining_length] + "..."
            else:
                break
        
        context_part = f"\n\n文档片段{i+1}（相似度：{result['similarity']:.3f}）：\n{content}"
        context_parts.append(context_part)
        current_length += len(context_part)
    
    # 添加用户问题
    user_question = f"\n\n用户问题：{query}\n\n请基于上述文档内容回答："
    context_parts.append(user_question)
    
    return "".join(context_parts)
```

## 4. 前后端交互时序图

### 4.1 用户登录时序图
```
用户 -> 前端: 输入用户名密码
前端 -> 后端: POST /api/user/login
后端 -> MySQL: 查询用户信息
MySQL -> 后端: 返回用户数据
后端 -> 后端: 验证密码
后端 -> 后端: 生成JWT Token
后端 -> 前端: 返回Token和用户信息
前端 -> 前端: 存储Token到LocalStorage
前端 -> 用户: 显示登录成功，跳转主页
```

### 4.2 文档上传处理时序图
```
用户 -> 前端: 选择文件上传
前端 -> 后端: POST /api/document/upload (multipart)
后端 -> OSS: 上传文件到对象存储
OSS -> 后端: 返回文件URL
后端 -> MySQL: 保存文档元数据
后端 -> 异步队列: 发送文档处理任务
后端 -> 前端: 返回上传成功响应
异步处理器 -> OSS: 下载文件内容
异步处理器 -> Tika: 解析文档内容
异步处理器 -> 分块器: 文档分块处理
异步处理器 -> 向量化服务: 文本向量化
异步处理器 -> Milvus: 存储向量数据
异步处理器 -> MySQL: 更新处理状态
```

### 4.3 智能问答时序图
```
用户 -> 前端: 输入问题
前端 -> 后端: POST /api/chat/ask
后端 -> 向量化服务: 问题向量化
后端 -> Milvus: 向量相似度检索
Milvus -> 后端: 返回相关文档片段
后端 -> 上下文构建器: 构建RAG上下文
后端 -> 通义千问API: 调用大语言模型
通义千问API -> 后端: 返回生成的答案
后端 -> Redis: 缓存对话历史
后端 -> MySQL: 持久化对话记录
后端 -> 前端: 返回答案和引用信息
前端 -> 用户: 显示答案和相关文档
```

### 4.4 系统监控时序图
```
监控系统 -> 后端: 健康检查请求
后端 -> MySQL: 检查数据库连接
后端 -> Milvus: 检查向量数据库连接
后端 -> Redis: 检查缓存连接
后端 -> 监控系统: 返回系统状态
监控系统 -> 告警系统: 异常状态告警
告警系统 -> 运维人员: 发送告警通知
```

## 5. 缓存设计

### 5.1 多级缓存架构
```
应用层缓存 (Caffeine) -> Redis缓存 -> 数据库
    ↓
本地缓存：热点数据，1000条，5分钟过期
分布式缓存：用户会话，检索结果，30分钟过期
持久化存储：完整数据，永久存储
```

### 5.2 缓存策略设计
- **用户信息缓存**：登录后缓存用户基本信息，过期时间2小时
- **文档元数据缓存**：缓存文档列表和详情，过期时间1小时
- **检索结果缓存**：缓存相同查询的检索结果，过期时间30分钟
- **对话历史缓存**：缓存最近的对话记录，过期时间1小时
- **系统配置缓存**：缓存系统配置信息，手动刷新

## 6. 异常处理设计

### 6.1 异常分类和处理策略
- **业务异常**：参数校验失败、权限不足等，返回具体错误信息
- **系统异常**：数据库连接失败、第三方服务异常等，返回通用错误信息
- **网络异常**：超时、连接中断等，支持重试机制
- **数据异常**：数据不一致、格式错误等，记录详细日志

### 6.2 全局异常处理器设计
```java
@RestControllerAdvice
public class GlobalExceptionHandler {
    
    @ExceptionHandler(BusinessException.class)
    public Result handleBusinessException(BusinessException e) {
        log.warn("业务异常：{}", e.getMessage());
        return Result.error(e.getCode(), e.getMessage());
    }
    
    @ExceptionHandler(SystemException.class)
    public Result handleSystemException(SystemException e) {
        log.error("系统异常：", e);
        return Result.error(500, "系统繁忙，请稍后重试");
    }
}
```