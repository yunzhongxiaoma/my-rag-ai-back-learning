# 监控与运维文档

## 1. 监控体系概述

### 1.1 监控架构设计
```
┌─────────────────────────────────────────────────────────────┐
│                    监控数据采集层                              │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ ┌─────────┐ │
│  │ 应用监控     │ │ 系统监控     │ │ 数据库监控   │ │ 业务监控 │ │
│  │ (Micrometer)│ │ (Node Exp.) │ │ (MySQL Exp.)│ │(Custom) │ │
│  └─────────────┘ └─────────────┘ └─────────────┘ └─────────┘ │
├─────────────────────────────────────────────────────────────┤
│                    监控数据存储层                              │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ ┌─────────┐ │
│  │ Prometheus  │ │ InfluxDB    │ │ Elasticsearch│ │ MySQL   │ │
│  │ (指标存储)   │ │ (时序数据)   │ │ (日志存储)   │ │(元数据) │ │
│  └─────────────┘ └─────────────┘ └─────────────┘ └─────────┘ │
├─────────────────────────────────────────────────────────────┤
│                    监控展示和告警层                            │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ ┌─────────┐ │
│  │   Grafana   │ │ AlertManager│ │    Kibana   │ │ 钉钉/邮件│ │
│  │ (可视化)     │ │ (告警管理)   │ │ (日志分析)   │ │ (通知)  │ │
│  └─────────────┘ └─────────────┘ └─────────────┘ └─────────┘ │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 监控目标
- **系统可用性监控**：确保服务7×24小时稳定运行
- **性能指标监控**：实时监控系统性能和资源使用情况
- **业务指标监控**：监控核心业务功能的健康状态
- **异常告警机制**：及时发现和通知系统异常
- **容量规划支持**：为系统扩容提供数据支撑

## 2. 监控指标体系

### 2.1 系统基础指标

#### 2.1.1 CPU监控指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| cpu_usage_percent | CPU使用率 | >80% | 30秒 |
| cpu_load_average_1m | 1分钟平均负载 | >CPU核数*0.8 | 30秒 |
| cpu_load_average_5m | 5分钟平均负载 | >CPU核数*0.7 | 30秒 |
| cpu_load_average_15m | 15分钟平均负载 | >CPU核数*0.6 | 30秒 |

#### 2.1.2 内存监控指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| memory_usage_percent | 内存使用率 | >85% | 30秒 |
| memory_available_bytes | 可用内存大小 | <2GB | 30秒 |
| swap_usage_percent | 交换分区使用率 | >50% | 30秒 |
| jvm_memory_used_bytes | JVM内存使用量 | >堆内存*0.8 | 30秒 |
| jvm_memory_max_bytes | JVM最大内存 | - | 30秒 |

#### 2.1.3 磁盘监控指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| disk_usage_percent | 磁盘使用率 | >85% | 1分钟 |
| disk_free_bytes | 磁盘可用空间 | <10GB | 1分钟 |
| disk_io_read_bytes | 磁盘读取字节数 | - | 30秒 |
| disk_io_write_bytes | 磁盘写入字节数 | - | 30秒 |
| disk_io_util_percent | 磁盘IO使用率 | >80% | 30秒 |

#### 2.1.4 网络监控指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| network_receive_bytes | 网络接收字节数 | - | 30秒 |
| network_transmit_bytes | 网络发送字节数 | - | 30秒 |
| network_connections | 网络连接数 | >10000 | 30秒 |
| network_errors | 网络错误数 | >100/min | 30秒 |

### 2.2 应用性能指标

#### 2.2.1 HTTP接口指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| http_requests_total | HTTP请求总数 | - | 实时 |
| http_request_duration_seconds | HTTP请求响应时间 | P95>5s | 实时 |
| http_requests_per_second | HTTP请求QPS | - | 实时 |
| http_response_status_codes | HTTP响应状态码分布 | 5xx>5% | 实时 |
| http_concurrent_requests | HTTP并发请求数 | >1000 | 实时 |

#### 2.2.2 JVM性能指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| jvm_gc_collection_seconds | GC耗时 | >1s | 实时 |
| jvm_gc_collection_total | GC次数 | >100/min | 实时 |
| jvm_threads_current | 当前线程数 | >500 | 30秒 |
| jvm_threads_daemon | 守护线程数 | - | 30秒 |
| jvm_classes_loaded | 已加载类数量 | - | 1分钟 |

#### 2.2.3 连接池指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| hikaricp_connections_active | 活跃数据库连接数 | >80% | 30秒 |
| hikaricp_connections_idle | 空闲数据库连接数 | <5 | 30秒 |
| hikaricp_connections_pending | 等待连接数 | >10 | 30秒 |
| hikaricp_connections_timeout | 连接超时数 | >0 | 30秒 |
| redis_connections_active | Redis活跃连接数 | >80% | 30秒 |

### 2.3 业务监控指标

#### 2.3.1 用户行为指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| user_login_total | 用户登录次数 | - | 实时 |
| user_login_success_rate | 登录成功率 | <95% | 5分钟 |
| user_active_count | 活跃用户数 | - | 5分钟 |
| user_session_duration | 用户会话时长 | - | 实时 |

#### 2.3.2 文档处理指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| document_upload_total | 文档上传总数 | - | 实时 |
| document_upload_success_rate | 文档上传成功率 | <95% | 5分钟 |
| document_process_duration | 文档处理耗时 | P95>60s | 实时 |
| document_process_queue_size | 文档处理队列长度 | >100 | 1分钟 |
| document_vector_count | 向量化文档数量 | - | 5分钟 |

#### 2.3.3 问答服务指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| chat_requests_total | 问答请求总数 | - | 实时 |
| chat_response_time | 问答响应时间 | P95>10s | 实时 |
| chat_success_rate | 问答成功率 | <95% | 5分钟 |
| vector_search_duration | 向量检索耗时 | P95>2s | 实时 |
| llm_api_calls_total | LLM API调用次数 | - | 实时 |
| llm_api_error_rate | LLM API错误率 | >5% | 5分钟 |

### 2.4 数据库监控指标

#### 2.4.1 MySQL监控指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| mysql_up | MySQL服务状态 | =0 | 30秒 |
| mysql_connections | MySQL连接数 | >80% | 30秒 |
| mysql_slow_queries | 慢查询数量 | >10/min | 1分钟 |
| mysql_query_response_time | 查询响应时间 | P95>1s | 实时 |
| mysql_innodb_buffer_pool_hit_rate | InnoDB缓冲池命中率 | <95% | 1分钟 |

#### 2.4.2 Milvus监控指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| milvus_up | Milvus服务状态 | =0 | 30秒 |
| milvus_collection_entities | 集合实体数量 | - | 5分钟 |
| milvus_search_latency | 向量检索延迟 | P95>1s | 实时 |
| milvus_insert_latency | 向量插入延迟 | P95>5s | 实时 |
| milvus_memory_usage | Milvus内存使用量 | >80% | 1分钟 |

#### 2.4.3 Redis监控指标
| 指标名称 | 指标说明 | 告警阈值 | 监控频率 |
|---------|----------|----------|----------|
| redis_up | Redis服务状态 | =0 | 30秒 |
| redis_connected_clients | Redis连接客户端数 | >1000 | 30秒 |
| redis_memory_usage_bytes | Redis内存使用量 | >80% | 30秒 |
| redis_keyspace_hits_rate | 缓存命中率 | <80% | 1分钟 |
| redis_expired_keys | 过期键数量 | - | 1分钟 |

## 3. 日志采集规范

### 3.1 日志分类和级别

#### 3.1.1 日志级别定义
- **ERROR**：系统错误，需要立即处理
- **WARN**：警告信息，需要关注但不影响正常运行
- **INFO**：重要的业务流程信息
- **DEBUG**：详细的调试信息，仅在开发和测试环境使用

#### 3.1.2 日志分类
```
logs/
├── application.log          # 应用主日志
├── error.log               # 错误日志
├── access.log              # 访问日志
├── business.log            # 业务日志
├── performance.log         # 性能日志
├── security.log            # 安全日志
└── gc.log                  # GC日志
```

### 3.2 日志格式规范

#### 3.2.1 标准日志格式
```
[时间戳] [日志级别] [线程名] [类名:行号] [TraceId] - [日志内容]

示例：
2024-01-07 10:30:15.123 [INFO] [http-nio-8989-exec-1] [c.m.r.controller.ChatController:45] [trace-123456] - 用户[user123]发起问答请求: 什么是RAG?
```

#### 3.2.2 结构化日志格式 (JSON)
```json
{
  "timestamp": "2024-01-07T10:30:15.123Z",
  "level": "INFO",
  "thread": "http-nio-8989-exec-1",
  "logger": "com.my.rag.controller.ChatController",
  "traceId": "trace-123456",
  "spanId": "span-789012",
  "userId": "user123",
  "action": "chat_request",
  "message": "用户发起问答请求",
  "details": {
    "question": "什么是RAG?",
    "sessionId": "session-456789",
    "requestTime": 1704621015123
  }
}
```

### 3.3 关键业务日志

#### 3.3.1 用户行为日志
```java
// 用户登录日志
log.info("用户登录成功 - userId: {}, username: {}, ip: {}, userAgent: {}", 
    userId, username, clientIp, userAgent);

// 用户操作日志
log.info("用户操作 - userId: {}, action: {}, resource: {}, result: {}", 
    userId, action, resource, result);
```

#### 3.3.2 文档处理日志
```java
// 文档上传日志
log.info("文档上传 - userId: {}, fileName: {}, fileSize: {}, uploadTime: {}", 
    userId, fileName, fileSize, uploadTime);

// 文档处理日志
log.info("文档处理 - documentId: {}, status: {}, processTime: {}, chunkCount: {}", 
    documentId, status, processTime, chunkCount);
```

#### 3.3.3 问答服务日志
```java
// 问答请求日志
log.info("问答请求 - userId: {}, sessionId: {}, question: {}, responseTime: {}ms", 
    userId, sessionId, question, responseTime);

// 向量检索日志
log.info("向量检索 - query: {}, topK: {}, searchTime: {}ms, resultCount: {}", 
    query, topK, searchTime, resultCount);
```

### 3.4 日志配置

#### 3.4.1 Logback配置 (logback-spring.xml)
```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <!-- 控制台输出 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%level] [%thread] [%logger{36}:%line] [%X{traceId}] - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- 应用日志文件 -->
    <appender name="APPLICATION" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/application.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>logs/application.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>30</maxHistory>
            <totalSizeCap>10GB</totalSizeCap>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%level] [%thread] [%logger{36}:%line] [%X{traceId}] - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- 错误日志文件 -->
    <appender name="ERROR" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/error.log</file>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>logs/error.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>90</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%level] [%thread] [%logger{36}:%line] [%X{traceId}] - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- 业务日志文件 -->
    <appender name="BUSINESS" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/business.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>logs/business.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%level] [%thread] [%logger{36}:%line] [%X{traceId}] - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- 根日志配置 -->
    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="APPLICATION"/>
        <appender-ref ref="ERROR"/>
    </root>

    <!-- 业务日志配置 -->
    <logger name="com.my.rag.service" level="INFO" additivity="false">
        <appender-ref ref="BUSINESS"/>
        <appender-ref ref="CONSOLE"/>
    </logger>

    <!-- 第三方库日志级别 -->
    <logger name="org.springframework" level="WARN"/>
    <logger name="org.apache.http" level="WARN"/>
    <logger name="com.alibaba.druid" level="WARN"/>
</configuration>
```

## 4. 告警规则配置

### 4.1 告警级别定义

#### 4.1.1 告警严重程度
- **P0 (致命)**：服务完全不可用，需要立即处理
- **P1 (严重)**：核心功能异常，影响用户使用
- **P2 (警告)**：部分功能异常，需要关注
- **P3 (提醒)**：性能下降或资源使用异常

#### 4.1.2 告警通知方式
| 告警级别 | 通知方式 | 通知频率 | 通知对象 |
|---------|----------|----------|----------|
| P0 | 电话+短信+钉钉 | 立即，每5分钟重复 | 值班工程师+技术负责人 |
| P1 | 短信+钉钉+邮件 | 立即，每15分钟重复 | 值班工程师+开发团队 |
| P2 | 钉钉+邮件 | 立即，每30分钟重复 | 开发团队 |
| P3 | 邮件 | 立即，每小时重复 | 开发团队 |

### 4.2 系统告警规则

#### 4.2.1 服务可用性告警
```yaml
# Prometheus告警规则
groups:
- name: service_availability
  rules:
  - alert: ServiceDown
    expr: up{job="my-rag-ai-back"} == 0
    for: 1m
    labels:
      severity: P0
    annotations:
      summary: "服务不可用"
      description: "{{ $labels.instance }} 服务已停止运行超过1分钟"

  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
    for: 2m
    labels:
      severity: P1
    annotations:
      summary: "HTTP错误率过高"
      description: "5分钟内HTTP 5xx错误率超过5%: {{ $value }}"
```

#### 4.2.2 性能告警规则
```yaml
- name: performance_alerts
  rules:
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 5
    for: 3m
    labels:
      severity: P2
    annotations:
      summary: "响应时间过长"
      description: "95%的请求响应时间超过5秒: {{ $value }}s"

  - alert: HighCPUUsage
    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: P2
    annotations:
      summary: "CPU使用率过高"
      description: "{{ $labels.instance }} CPU使用率超过80%: {{ $value }}%"

  - alert: HighMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: P2
    annotations:
      summary: "内存使用率过高"
      description: "{{ $labels.instance }} 内存使用率超过85%: {{ $value }}%"
```

#### 4.2.3 业务告警规则
```yaml
- name: business_alerts
  rules:
  - alert: DocumentProcessingQueueHigh
    expr: document_process_queue_size > 100
    for: 10m
    labels:
      severity: P2
    annotations:
      summary: "文档处理队列积压"
      description: "文档处理队列长度超过100: {{ $value }}"

  - alert: LowChatSuccessRate
    expr: rate(chat_requests_success_total[10m]) / rate(chat_requests_total[10m]) < 0.95
    for: 5m
    labels:
      severity: P1
    annotations:
      summary: "问答成功率过低"
      description: "10分钟内问答成功率低于95%: {{ $value }}"

  - alert: MilvusConnectionFailed
    expr: milvus_up == 0
    for: 1m
    labels:
      severity: P0
    annotations:
      summary: "Milvus连接失败"
      description: "无法连接到Milvus向量数据库"
```

### 4.3 告警通知配置

#### 4.3.1 AlertManager配置
```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'password'

route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default'
  routes:
  - match:
      severity: P0
    receiver: 'critical'
    repeat_interval: 5m
  - match:
      severity: P1
    receiver: 'warning'
    repeat_interval: 15m

receivers:
- name: 'default'
  email_configs:
  - to: 'team@example.com'
    subject: '[{{ .Status }}] {{ .GroupLabels.alertname }}'
    body: |
      {{ range .Alerts }}
      告警: {{ .Annotations.summary }}
      描述: {{ .Annotations.description }}
      时间: {{ .StartsAt }}
      {{ end }}

- name: 'critical'
  webhook_configs:
  - url: 'http://dingtalk-webhook/critical'
  email_configs:
  - to: 'oncall@example.com'
    subject: '[紧急] {{ .GroupLabels.alertname }}'

- name: 'warning'
  webhook_configs:
  - url: 'http://dingtalk-webhook/warning'
```

## 5. 故障排查流程

### 5.1 故障分类和处理流程

#### 5.1.1 故障分类
- **服务不可用**：应用无法启动或完全停止响应
- **性能问题**：响应时间过长、吞吐量下降
- **功能异常**：特定功能无法正常工作
- **数据问题**：数据丢失、数据不一致
- **安全问题**：安全漏洞、异常访问

#### 5.1.2 故障处理流程
```
故障发现 → 故障确认 → 影响评估 → 应急处理 → 根因分析 → 永久修复 → 总结改进
    ↓         ↓         ↓         ↓         ↓         ↓         ↓
  监控告警   人工验证   业务影响   临时恢复   深入调查   代码修复   文档更新
  用户反馈   日志分析   用户数量   服务重启   日志分析   测试验证   流程优化
```

### 5.2 常见故障排查手册

#### 5.2.1 服务启动失败
```bash
# 1. 检查应用日志
tail -f logs/application.log
grep -i error logs/application.log

# 2. 检查端口占用
netstat -tlnp | grep 8989
lsof -i :8989

# 3. 检查Java进程
jps -l
ps aux | grep java

# 4. 检查配置文件
cat application.yml
env | grep -E "(DB_|REDIS_|MILVUS_)"

# 5. 检查依赖服务
curl -f http://localhost:3306  # MySQL
curl -f http://localhost:6379  # Redis
curl -f http://localhost:19530 # Milvus
```

#### 5.2.2 数据库连接问题
```bash
# 1. 检查数据库服务状态
systemctl status mysql
docker ps | grep mysql

# 2. 测试数据库连接
mysql -h localhost -P 3306 -u root -p
telnet localhost 3306

# 3. 检查连接池状态
curl http://localhost:8989/actuator/metrics/hikaricp.connections.active

# 4. 检查数据库日志
tail -f /var/log/mysql/error.log
docker logs mysql-container

# 5. 检查网络连通性
ping database-host
traceroute database-host
```

#### 5.2.3 Milvus连接问题
```bash
# 1. 检查Milvus服务状态
docker ps | grep milvus
curl http://localhost:9091/healthz

# 2. 检查Milvus日志
docker logs milvus-standalone

# 3. 检查集合状态
# 使用Milvus客户端工具检查集合信息

# 4. 检查向量数据
# 验证向量数据的完整性和一致性

# 5. 重建索引
# 如果索引损坏，重新构建向量索引
```

#### 5.2.4 内存溢出问题
```bash
# 1. 生成堆转储文件
jmap -dump:format=b,file=heapdump.hprof <pid>

# 2. 分析内存使用
jstat -gc <pid> 5s
jstat -gccapacity <pid>

# 3. 查看GC日志
tail -f logs/gc.log

# 4. 分析堆转储
# 使用Eclipse MAT或VisualVM分析堆转储文件

# 5. 调整JVM参数
# 根据分析结果调整堆内存大小和GC策略
```

### 5.3 故障排查工具

#### 5.3.1 系统监控工具
```bash
# 系统资源监控
top                    # 实时系统资源使用情况
htop                   # 增强版top
iotop                  # IO使用情况
nethogs                # 网络使用情况

# 进程分析
ps aux                 # 进程列表
pstree                 # 进程树
lsof                   # 打开文件列表
strace -p <pid>        # 系统调用跟踪
```

#### 5.3.2 Java应用诊断工具
```bash
# JVM工具
jps                    # Java进程列表
jinfo <pid>            # JVM配置信息
jstat -gc <pid>        # GC统计信息
jstack <pid>           # 线程堆栈信息
jmap -histo <pid>      # 堆内存对象统计

# 性能分析
java -XX:+PrintGCDetails -XX:+PrintGCTimeStamps
java -XX:+HeapDumpOnOutOfMemoryError
```

#### 5.3.3 网络诊断工具
```bash
# 网络连通性
ping <host>            # 网络连通性测试
telnet <host> <port>   # 端口连通性测试
nc -zv <host> <port>   # 端口扫描

# 网络分析
netstat -tlnp          # 网络连接状态
ss -tlnp               # 现代版netstat
tcpdump -i eth0        # 网络包捕获
wireshark              # 网络包分析
```

## 6. 版本回滚步骤

### 6.1 回滚策略

#### 6.1.1 回滚触发条件
- 新版本部署后出现严重功能问题
- 系统性能显著下降
- 数据一致性问题
- 安全漏洞发现
- 用户体验严重影响

#### 6.1.2 回滚决策流程
```
问题发现 → 影响评估 → 回滚决策 → 执行回滚 → 验证恢复 → 问题分析
    ↓         ↓         ↓         ↓         ↓         ↓
  监控告警   业务影响   技术评估   自动/手动   功能测试   根因分析
  用户反馈   数据风险   时间窗口   数据备份   性能验证   改进措施
```

### 6.2 自动回滚机制

#### 6.2.1 健康检查回滚
```bash
#!/bin/bash
# auto-rollback.sh - 自动回滚脚本

HEALTH_CHECK_URL="http://localhost:8989/actuator/health"
MAX_RETRIES=5
RETRY_INTERVAL=30

check_health() {
    local retries=0
    while [ $retries -lt $MAX_RETRIES ]; do
        if curl -f $HEALTH_CHECK_URL > /dev/null 2>&1; then
            echo "健康检查通过"
            return 0
        fi
        
        echo "健康检查失败，等待重试..."
        sleep $RETRY_INTERVAL
        retries=$((retries + 1))
    done
    
    echo "健康检查失败，触发自动回滚"
    return 1
}

rollback() {
    echo "开始自动回滚..."
    
    # 停止当前版本
    ./stop.sh
    
    # 恢复备份版本
    cp -r /opt/backup/latest/* /opt/my-rag-ai/
    
    # 启动备份版本
    ./start.sh
    
    # 验证回滚结果
    if check_health; then
        echo "自动回滚成功"
        # 发送通知
        curl -X POST "https://oapi.dingtalk.com/robot/send" \
             -H "Content-Type: application/json" \
             -d '{"msgtype": "text", "text": {"content": "系统已自动回滚到上一版本"}}'
    else
        echo "自动回滚失败，需要人工介入"
        exit 1
    fi
}

# 执行健康检查
if ! check_health; then
    rollback
fi
```

### 6.3 手动回滚步骤

#### 6.3.1 应用回滚步骤
```bash
# 1. 停止当前应用
sudo systemctl stop my-rag-ai-back
# 或者
pkill -f my-rag-ai-back

# 2. 备份当前版本（如果需要）
cp -r /opt/my-rag-ai /opt/backup/failed-$(date +%Y%m%d-%H%M%S)

# 3. 恢复上一版本
rm -rf /opt/my-rag-ai/*
cp -r /opt/backup/previous-version/* /opt/my-rag-ai/

# 4. 恢复配置文件
cp /opt/backup/config/application.yml /opt/my-rag-ai/config/

# 5. 启动应用
sudo systemctl start my-rag-ai-back

# 6. 验证服务状态
curl http://localhost:8989/actuator/health
```

#### 6.3.2 数据库回滚步骤
```bash
# 1. 停止应用服务
sudo systemctl stop my-rag-ai-back

# 2. 备份当前数据库
mysqldump -u root -p my_rag > /opt/backup/db-backup-$(date +%Y%m%d-%H%M%S).sql

# 3. 恢复数据库备份
mysql -u root -p my_rag < /opt/backup/db-backup-previous.sql

# 4. 验证数据完整性
mysql -u root -p -e "SELECT COUNT(*) FROM my_rag.tb_user;"

# 5. 重启应用服务
sudo systemctl start my-rag-ai-back
```

#### 6.3.3 向量数据回滚
```bash
# 1. 停止Milvus相关操作
# 确保没有正在进行的向量操作

# 2. 备份当前向量数据
# 使用Milvus备份工具或数据导出功能

# 3. 恢复向量数据
# 从备份中恢复向量集合和索引

# 4. 重建索引（如果需要）
# 重新构建向量索引以确保检索性能

# 5. 验证向量数据
# 执行测试查询验证数据完整性
```

### 6.4 回滚验证清单

#### 6.4.1 功能验证
- [ ] 用户登录功能正常
- [ ] 文档上传功能正常
- [ ] 文档处理功能正常
- [ ] 问答功能正常
- [ ] 向量检索功能正常
- [ ] 用户权限控制正常

#### 6.4.2 性能验证
- [ ] 响应时间恢复正常
- [ ] 系统资源使用正常
- [ ] 数据库连接正常
- [ ] 缓存功能正常
- [ ] 第三方服务调用正常

#### 6.4.3 数据验证
- [ ] 用户数据完整
- [ ] 文档数据完整
- [ ] 向量数据完整
- [ ] 对话历史完整
- [ ] 系统配置正确

### 6.5 回滚后处理

#### 6.5.1 通知相关人员
```bash
# 发送回滚通知
curl -X POST "https://oapi.dingtalk.com/robot/send" \
     -H "Content-Type: application/json" \
     -d '{
       "msgtype": "markdown",
       "markdown": {
         "title": "系统回滚通知",
         "text": "## 系统回滚通知\n\n**回滚时间**: '$(date)'\n\n**回滚原因**: 新版本部署后出现功能异常\n\n**当前状态**: 已回滚到上一稳定版本\n\n**影响范围**: 全部用户\n\n**后续计划**: 分析问题原因，修复后重新部署"
       }
     }'
```

#### 6.5.2 问题分析和改进
1. **根因分析**：深入分析导致回滚的根本原因
2. **流程改进**：优化部署和测试流程
3. **监控完善**：增强监控和告警机制
4. **文档更新**：更新操作手册和应急预案
5. **团队培训**：加强团队的故障处理能力

#### 6.5.3 预防措施
- 加强测试覆盖率和测试质量
- 完善灰度发布和蓝绿部署机制
- 建立更完善的监控和告警体系
- 定期进行故障演练和应急响应训练
- 建立完整的版本管理和回滚机制